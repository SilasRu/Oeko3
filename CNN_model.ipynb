{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CNN_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SilasRu/Oeko3/blob/master/CNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qquc3oOtWXrX",
        "colab_type": "text"
      },
      "source": [
        "# Speaker Recognition CNN #\n",
        "\n",
        "The Following sections show the code used for the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pc5fHJnWoVF",
        "colab_type": "text"
      },
      "source": [
        "**Cloning the repository**\n",
        "\n",
        "\n",
        "The repository is cloned to gain access to the preprocessed autio files, spectrograms and functions.\n",
        "\n",
        "\n",
        "\n",
        "*   Functions used are found in src/data_utils\n",
        "*   Spectrograms and audio files are found in data/train and test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NktsVmfFOXGY",
        "colab_type": "code",
        "outputId": "e054e99f-80d5-470b-8462-674907f905ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/SilasRu/Oeko3.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Oeko3'...\n",
            "remote: Enumerating objects: 378, done.\u001b[K\n",
            "remote: Counting objects: 100% (378/378), done.\u001b[K\n",
            "remote: Compressing objects: 100% (357/357), done.\u001b[K\n",
            "remote: Total 22912 (delta 43), reused 343 (delta 19), pack-reused 22534\u001b[K\n",
            "Receiving objects: 100% (22912/22912), 1.26 GiB | 36.43 MiB/s, done.\n",
            "Resolving deltas: 100% (730/730), done.\n",
            "Checking out files: 100% (20270/20270), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy-TZeifJcVr",
        "colab_type": "text"
      },
      "source": [
        "**Importing packages and path handling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ME5HE0VjMiF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "650bb4a2-13ac-452a-bb37-ae6862e53b91"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import  ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "import keras.models as km\n",
        "import keras.layers as kl\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import random\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Activation, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Append training path\n",
        "sys.path.append(\"[Oeko3\\\\data\\\\train\\\\spectrograms]\")\n",
        "path = os.path.join('Oeko3', 'data', 'train', 'spectrograms')\n",
        "persons = sorted(os.listdir(path))\n",
        "\n",
        "# Append test path\n",
        "sys.path.append(\"[Oeko3\\\\data\\\\test\\\\spectrograms]\")\n",
        "path_test = os.path.join('Oeko3', 'data', 'test', 'spectrograms')\n",
        "persons_test = os.listdir(path_test)\n",
        "\n",
        "# Get speaker list\n",
        "sys.path.append(\"[Oeko3\\\\data\\\\test]\")\n",
        "speaker_list = os.path.join('Oeko3', 'data', 'test', 'speaker_list.csv')\n",
        "sys.path.append('Oeko3/src')\n",
        "\n",
        "# Import data_util function to convert speaker list\n",
        "import data_utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgApGTcnXa4b",
        "colab_type": "text"
      },
      "source": [
        "The persons available in the folder are the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03ULxFs6XsNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fef1563-768e-47cb-a41c-350fad324cf8"
      },
      "source": [
        "persons"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['berset', 'goess', 'projer', 'roesti', 'rytz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gezopmpJRhO",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "**Converting train and test spectrograms to matrices**\n",
        "\n",
        "The following two functions convert a given amount of images to a matrix, that is then used in the Neural Network.\n",
        "To completely randomize the input in the training set, a sample folder of the available speakers is chosen, and from this folder, 10 random images are collected for each loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71rBkF3rkQuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_train(size):\n",
        "  x_train = []\n",
        "  y_train = []\n",
        "  errors = 0\n",
        "  for i in range(size):\n",
        "      sample = random.randint(0,4)\n",
        "      tempdir = os.path.join(path, persons[sample])\n",
        "      tempfiles = os.listdir(tempdir)\n",
        "      amount = 0\n",
        "      while amount < 10:  \n",
        "          sample_img = random.sample(tempfiles, 1)\n",
        "          temp_img = load_img(os.path.join(tempdir,sample_img[0]))\n",
        "          temp_x = img_to_array(temp_img)/255.\n",
        "          if temp_x.shape== (480,640,3):\n",
        "            temp_x = temp_x.reshape((1,)+temp_x.shape)\n",
        "            if i ==0 and amount == 0:  \n",
        "                x_train = temp_x\n",
        "            else:\n",
        "              x_train = np.concatenate((x_train,temp_x),  axis = 0)\n",
        "            y_train.append(sample)\n",
        "            amount +=1\n",
        "          else:\n",
        "            errors += 1\n",
        "  return x_train, y_train          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtUs4-0BYQra",
        "colab_type": "text"
      },
      "source": [
        "In the test set, the preprocessed spectrograms are loaded and converted to an array. This together with the corresponding speaker, loaded from the speaker_list csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJs3vbE1JN8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_test(speaker_list, range_start, range_stop):\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "  converter = data_utils.Utils()\n",
        "  y_test_list = converter.create_y_test(speaker_list)[range_start: range_stop]\n",
        "  \n",
        "  first_obs = True\n",
        "  tempdir = path_test\n",
        "  tempfiles = sorted(persons_test)[range_start: range_stop]\n",
        "  \n",
        "  for index, img in enumerate(tempfiles):\n",
        "      temp_img = load_img(os.path.join(tempdir,img))\n",
        "      temp_x = img_to_array(temp_img)/255.\n",
        "      temp_x = temp_x.reshape((1,)+temp_x.shape)\n",
        "      if y_test_list[index] != 5:\n",
        "        if first_obs:\n",
        "            x_test = temp_x\n",
        "            first_obs = False\n",
        "        else:\n",
        "          x_test = np.concatenate((x_test,temp_x),  axis = 0)     \n",
        "        y_test.append(y_test_list[index])\n",
        "  \n",
        "  return x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hko7k3fKJkXt",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "**CNN build**\n",
        "\n",
        "\n",
        "Here we create the core CNN that is used to train the model and perform predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RedVXj7cme4w",
        "colab_type": "code",
        "outputId": "8c104163-8c8a-4ba6-d7d5-73148c4d2927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#create model\n",
        "model = Sequential()\n",
        "#add model layers\n",
        "model.add(Conv2D(128,strides=3, kernel_size=3, activation=\"relu\",\n",
        "                 input_shape= (480, 640, 3)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64,strides=3 ,kernel_size=3, activation=\"sigmoid\"))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(len(persons), activation=\"softmax\"))\n",
        "\n",
        "#compile model using accuracy to measure model performance\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-f6ivLiJsZs",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "**Fitting the model on the training set**\n",
        "\n",
        "The training is done by training 20 epochs on 200 random images in the training folder, this 40 times. We chose not to train on all available files at one time due to the high memory cost of image to matrix conversions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBboXyW1mqoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "episodes = 40\n",
        "for i in range(episodes):\n",
        "  x_train, y_train = convert_train(20)\n",
        "  y_cat = to_categorical(y_train, num_classes=5)\n",
        "  model.fit(x_train, y_cat, validation_split = 0.2, epochs=20, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvkdAJMtJwp1",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "**Prediction on the test set and confusion matrix**\n",
        "\n",
        "In the last step, the predictions are made on the SRF Arena test spectrograms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLuj3wSlwmq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "y_test_list = []\n",
        "x_test, y_test = convert_test(speaker_list, 0,4500)\n",
        "prediction = model.predict_classes(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43vg3FN-GWJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54a598ba-16b7-45a4-d5c9-3ae1924ab5d8"
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3477"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDPlDZHDGUPh",
        "colab_type": "code",
        "outputId": "573ea420-8bd8-4b4a-c545-e7777faeb501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "prediction = model.predict_classes(x_test)\n",
        "print(confusion_matrix(y_test_list, predictions))\n",
        "print(accuracy_score(y_test_list, predictions))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1314   64   52   88   13]\n",
            " [  62  298    5   32   17]\n",
            " [ 101   33  328  102   14]\n",
            " [ 140   18   83  291   17]\n",
            " [  25   70   14   16  280]]\n",
            "0.722174288179465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T_5Ik7YZt-K",
        "colab_type": "text"
      },
      "source": [
        "We achieve an accuracy of 72%, with room for additional improvements."
      ]
    }
  ]
}