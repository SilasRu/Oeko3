{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CNN_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SilasRu/Oeko3/blob/master/Copy_of_CNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "NktsVmfFOXGY",
        "colab_type": "code",
        "outputId": "dd52e52f-d2c1-4ad7-cc50-45b84b6bf089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SilasRu/Oeko3.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Oeko3'...\n",
            "remote: Enumerating objects: 372, done.\u001b[K\n",
            "remote: Counting objects: 100% (372/372), done.\u001b[K\n",
            "remote: Compressing objects: 100% (365/365), done.\u001b[K\n",
            "remote: Total 6587 (delta 16), reused 355 (delta 6), pack-reused 6215\u001b[K\n",
            "Receiving objects: 100% (6587/6587), 472.96 MiB | 36.50 MiB/s, done.\n",
            "Resolving deltas: 100% (99/99), done.\n",
            "Checking out files: 100% (5154/5154), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zy-TZeifJcVr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing packages and path handling**"
      ]
    },
    {
      "metadata": {
        "id": "5ME5HE0VjMiF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import  ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "import keras.models as km\n",
        "import keras.layers as kl\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Activation, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TuY2eVCKkCMb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"[Oeko3\\\\data\\\\train\\\\spectrograms]\")\n",
        "path = os.path.join('Oeko3', 'data', 'train', 'spectrograms')\n",
        "persons = os.listdir(path)\n",
        "\n",
        "sys.path.append(\"[Oeko3\\\\data\\\\test\\\\spectrograms]\")\n",
        "path_test = os.path.join('Oeko3', 'data', 'test', 'spectrograms')\n",
        "persons_test = os.listdir(path_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gezopmpJRhO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Converting train and test spectrograms to matrices**"
      ]
    },
    {
      "metadata": {
        "id": "71rBkF3rkQuR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dic = {}\n",
        "x_train = []\n",
        "y_train = []\n",
        "errors = 0\n",
        "for i in range(len(persons)):\n",
        "    tempdir = os.path.join(path, persons[i])\n",
        "    tempfiles = os.listdir(tempdir)\n",
        "    tempimglist = []\n",
        "#     for j in range(len(tempfiles)):\n",
        "    for j in range(90):\n",
        "        temp_img = load_img(os.path.join(tempdir,tempfiles[j]))\n",
        "        temp_x = img_to_array(temp_img)/255.\n",
        "        tempimglist.append(temp_x)\n",
        "        if i ==0 and j == 0:\n",
        "            temp_x = temp_x.reshape((1,)+temp_x.shape)\n",
        "            x_train = temp_x\n",
        "            y_train.append(i)\n",
        "        else:\n",
        "            try:\n",
        "                temp_x = temp_x.reshape((1,)+temp_x.shape)\n",
        "                print(str(persons[i])+'__'+str(tempfiles[j])+', shape:  '+str(temp_x.shape))\n",
        "                x_train = np.concatenate((x_train,temp_x),  axis = 0)\n",
        "                y_train.append(i)\n",
        "            except:\n",
        "                errors += 1\n",
        "                print(str(persons[i])+'__'+str(tempfiles[j]+'   INVALID SHAPE. CAN NOT ADD TO TRAINING SET'))\n",
        "    train_dic[persons[i]] = np.array(tempimglist)\n",
        "\n",
        "print(str(errors)+' ERRORS THAT CAN NOT BE ADDED TO TRAINING SET')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kJs3vbE1JN8T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dic = {}\n",
        "x_test = []\n",
        "y_test = []\n",
        "errors = 0\n",
        "for i in range(len(persons_test)):\n",
        "    tempdir = os.path.join(path_test, persons_test[i])\n",
        "    tempfiles = os.listdir(tempdir)\n",
        "    tempimglist = []\n",
        "    for j in range(len(tempfiles)):\n",
        "        temp_img = load_img(os.path.join(tempdir,tempfiles[j]))\n",
        "        temp_x = img_to_array(temp_img)/255.\n",
        "        tempimglist.append(temp_x)\n",
        "        if i ==0 and j == 0:\n",
        "            temp_x = temp_x.reshape((1,)+temp_x.shape)\n",
        "            x_test = temp_x\n",
        "            y_test.append(i)\n",
        "        else:\n",
        "            try:\n",
        "                temp_x = temp_x.reshape((1,)+temp_x.shape)\n",
        "                print(str(persons[i])+'__'+str(tempfiles[j])+', shape:  '+str(temp_x.shape))\n",
        "                x_test = np.concatenate((x_test,temp_x),  axis = 0)\n",
        "                y_test.append(i)\n",
        "            except:\n",
        "                errors += 1\n",
        "                print(str(persons_test[i])+'__'+str(tempfiles[j]+'   INVALID SHAPE. CAN NOT ADD TO TRAINING SET'))\n",
        "    train_dic[persons_test[i]] = np.array(tempimglist)\n",
        "\n",
        "print(str(errors)+' ERRORS THAT CAN NOT BE ADDED TO TRAINING SET')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hko7k3fKJkXt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CNN build**"
      ]
    },
    {
      "metadata": {
        "id": "RedVXj7cme4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fe2b5005-0a2d-4834-f0cb-3dd23236b77e"
      },
      "cell_type": "code",
      "source": [
        "X_train = x_train\n",
        "y_lab = np.array(y_train)\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "#create model\n",
        "model = Sequential()\n",
        "#add model layers\n",
        "model.add(Conv2D(64,strides=3, kernel_size=3, activation=\"relu\",\n",
        "                 input_shape= X_train[0].shape))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32,strides=3 ,kernel_size=3, activation=\"sigmoid\"))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(len(persons), activation=\"softmax\"))\n",
        "\n",
        "#compile model using accuracy to measure model performance\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4-f6ivLiJsZs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Fitting the model on the training set**"
      ]
    },
    {
      "metadata": {
        "id": "xBboXyW1mqoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_split = 0.2, epochs=20, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wvkdAJMtJwp1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Prediction on the test set and confusion matrix**"
      ]
    },
    {
      "metadata": {
        "id": "sDPlDZHDGUPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8ddd442c-3eda-4937-e344-66cc86175da7"
      },
      "cell_type": "code",
      "source": [
        "prediction = model.predict_classes(x_test)\n",
        "print(confusion_matrix(y_test, prediction))\n",
        "print(accuracy_score(y_test, prediction))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[30  0  2  0]\n",
            " [ 0 48  2  0]\n",
            " [ 2  1 47  0]\n",
            " [ 0  0  0 50]]\n",
            "0.9615384615384616\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}